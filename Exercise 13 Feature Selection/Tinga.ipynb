{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection Exercie\n",
    "\n",
    "In this exercise, we will apply Feature Selection to a Iris flowers dataset, where the target variable is the Species. Essentially, our goal is to identify the features that are most relevant in discerning the species of each Iris flower. The dataset is from: https://www.kaggle.com/datasets/uciml/iris\n",
    "You can view the demos found in the repository for some methods.\n",
    "\n",
    "1. Load the dataset from the exercise's Github Repository (Iris.csv)\n",
    "2. Using buisness logic/common sense, drop features that are surely irrevelvant to the target variable.\n",
    "3. Preprocess your data (split data into training and testing)\n",
    "4. Apply feature selection using any 3 (three) different methods:\n",
    "(Hint) Since the target variable, Species, is categorical, you can apply the numerical methods on the numerical predictor variables against themselves instead to reduce Feature redundancy.\n",
    "    - Pearson's correlation coefficient (r)\n",
    "    - Kendall's tau (Ï„)\n",
    "    - Mutual Information (MI)\n",
    "    - Logistic Regression with L1 penalty\n",
    "    - Any other method/model of Feature Selection....\n",
    "6. Compare the results of each feature selection method:\n",
    "    - What features did you manually dropped before applying the feature selection methods? Explain why.\n",
    "    - Are there any common features selected across multiple methods?\n",
    "    - Can you explain why certain features were selected based on their characteristics?\n",
    "(Optional) Visualize the importance of features using techniques like bar charts or heatmaps to make it easier to compare.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import mutual_info_classif, mutual_info_regression\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, mutual_info_classif, chi2\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from scipy.stats import pearsonr, kendalltau\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Iris.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = LabelEncoder()\n",
    "data[\"FlowerColour\"] = labels.fit_transform(data[\"FlowerColour\"])\n",
    "data[\"Species\"] = labels.fit_transform(data[\"Species\"])\n",
    "\n",
    "X = data.drop(\"Species\", axis=1)\n",
    "y = data[\"Species\"]\n",
    "\n",
    "X = X.drop(['Id','MonthCollected','YearCollected'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mutual Info Selected Features: Index(['PetalLengthCm', 'PetalWidthCm', 'StigmaLegnth'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#Using MUTUAL_INFO\n",
    "selector = SelectKBest(mutual_info_classif, k=3)\n",
    "selected_features = selector.fit(X_train, y_train).get_support(indices=True)\n",
    "print(\"Mutual Info Selected Features:\", X_train.columns[selected_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANOVA Selected Features: Index(['PetalLengthCm', 'PetalWidthCm', 'StigmaLegnth'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#Using ANOVA F-test\n",
    "selector = SelectKBest(f_classif, k=3)\n",
    "selected_features = selector.fit(X_train, y_train).get_support(indices=True)\n",
    "print(\"ANOVA Selected Features:\", X_train.columns[selected_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chi-squared Info Selected Features: Index(['PetalLengthCm', 'PetalWidthCm', 'StigmaLegnth'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#Using Chi-squared\n",
    "selector = SelectKBest(chi2, k=3)\n",
    "selected_features = selector.fit(X_train, y_train).get_support(indices=True)\n",
    "print(\"Chi-squared Info Selected Features:\", X_train.columns[selected_features])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
