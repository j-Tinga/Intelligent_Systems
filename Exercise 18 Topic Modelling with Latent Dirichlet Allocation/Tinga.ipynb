{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5569ebe-d9bb-4017-a5d6-fd7b87c8307b",
   "metadata": {},
   "source": [
    "# LDA DEMO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b481af9-3e7a-4407-8bde-8d01b5d3b738",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[E050] Can't find model 'en_core_web_sm'. It doesn't seem to be a Python package or a valid path to a data directory.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpprint\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pprint\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Load spaCy's English NLP model\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m nlp \u001b[38;5;241m=\u001b[39m \u001b[43mspacy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43men_core_web_sm\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Tinga\\Documents\\Intelligent\\Intelligent_Systems\\.conda\\Lib\\site-packages\\spacy\\__init__.py:51\u001b[0m, in \u001b[0;36mload\u001b[1;34m(name, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(\n\u001b[0;32m     28\u001b[0m     name: Union[\u001b[38;5;28mstr\u001b[39m, Path],\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     34\u001b[0m     config: Union[Dict[\u001b[38;5;28mstr\u001b[39m, Any], Config] \u001b[38;5;241m=\u001b[39m util\u001b[38;5;241m.\u001b[39mSimpleFrozenDict(),\n\u001b[0;32m     35\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Language:\n\u001b[0;32m     36\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Load a spaCy model from an installed package or a local path.\u001b[39;00m\n\u001b[0;32m     37\u001b[0m \n\u001b[0;32m     38\u001b[0m \u001b[38;5;124;03m    name (str): Package name or model path.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;124;03m    RETURNS (Language): The loaded nlp object.\u001b[39;00m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 51\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     52\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvocab\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvocab\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdisable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m        \u001b[49m\u001b[43menable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexclude\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     57\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     58\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Tinga\\Documents\\Intelligent\\Intelligent_Systems\\.conda\\Lib\\site-packages\\spacy\\util.py:472\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(name, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[0;32m    470\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m OLD_MODEL_SHORTCUTS:\n\u001b[0;32m    471\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(Errors\u001b[38;5;241m.\u001b[39mE941\u001b[38;5;241m.\u001b[39mformat(name\u001b[38;5;241m=\u001b[39mname, full\u001b[38;5;241m=\u001b[39mOLD_MODEL_SHORTCUTS[name]))  \u001b[38;5;66;03m# type: ignore[index]\u001b[39;00m\n\u001b[1;32m--> 472\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(Errors\u001b[38;5;241m.\u001b[39mE050\u001b[38;5;241m.\u001b[39mformat(name\u001b[38;5;241m=\u001b[39mname))\n",
      "\u001b[1;31mOSError\u001b[0m: [E050] Can't find model 'en_core_web_sm'. It doesn't seem to be a Python package or a valid path to a data directory."
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import spacy\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "from pprint import pprint\n",
    "\n",
    "# Load spaCy's English NLP model\n",
    "nlp = spacy.load('en_core_web_sm')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56591d37-365b-4b44-b0a2-f00900104823",
   "metadata": {},
   "source": [
    "# Sample documents for demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72f3c3a-5ca9-4272-8d27-c5af9b0754c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "documents = [\n",
    "    \"Hallo Amongus\",\n",
    "    \"Sample documents for demonstration\",\n",
    "    \"Officer K (Ryan Gosling), a new blade runner for the Los Angeles Police Department, unearths a long-buried secret that has the potential to plunge what's left of society into chaos. His discovery leads him on a quest to find Rick Deckard (Harrison Ford), a former blade runner who's been missing for 30 years.\",\n",
    "    \"Barbie and Ken are having the time of their lives in the colorful and seemingly perfect world of Barbie Land. However, when they get a chance to go to the real world, they soon discover the joys and perils of living among humans..\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b04ad12-95ea-4a0a-ac49-f4ee9fbaeee2",
   "metadata": {},
   "source": [
    "# Preprocess the documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97f87a2-a9f4-4557-aef6-c921bda4e2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def preprocess(text):\n",
    "    # Tokenize and lemmatize using spaCy\n",
    "    doc = nlp(text)\n",
    "    tokens = [token.lemma_ for token in doc if not token.is_stop and token.is_alpha]\n",
    "    return tokens\n",
    "\n",
    "# Apply preprocessing to all documents\n",
    "processed_documents = [preprocess(doc) for doc in documents]\n",
    "\n",
    "# Create a dictionary and corpus for LDA\n",
    "dictionary = corpora.Dictionary(processed_documents)\n",
    "corpus = [dictionary.doc2bow(doc) for doc in processed_documents]\n",
    "\n",
    "# Build LDA model\n",
    "lda_model = gensim.models.LdaModel(corpus, num_topics=3, id2word=dictionary, passes=15)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05542fa2-2765-4327-bb81-27e6b2d629ef",
   "metadata": {},
   "source": [
    "# Print topics and their keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f567bec-dfdf-4dd8-80b3-169eb11aa978",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  '0.157*\"topic\" + 0.089*\"modeling\" + 0.089*\"identify\" + 0.089*\"corpus\" + '\n",
      "  '0.089*\"text\" + 0.089*\"present\" + 0.022*\"library\" + 0.022*\"similarity\" + '\n",
      "  '0.022*\"Gensim\" + 0.022*\"document\"'),\n",
      " (1,\n",
      "  '0.061*\"popular\" + 0.061*\"document\" + 0.061*\"Python\" + 0.061*\"Gensim\" + '\n",
      "  '0.061*\"similarity\" + 0.061*\"library\" + 0.061*\"model\" + 0.061*\"Latent\" + '\n",
      "  '0.061*\"Dirichlet\" + 0.061*\"Allocation\"'),\n",
      " (2,\n",
      "  '0.095*\"natural\" + 0.095*\"subfield\" + 0.095*\"artificial\" + '\n",
      "  '0.095*\"processing\" + 0.095*\"intelligence\" + 0.095*\"language\" + '\n",
      "  '0.024*\"topic\" + 0.024*\"modeling\" + 0.024*\"probabilistic\" + '\n",
      "  '0.024*\"generative\"')]\n"
     ]
    }
   ],
   "source": [
    "pprint(lda_model.print_topics())"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c7bc7e95-7c82-4bcd-994e-caf4d5498317",
   "metadata": {},
   "source": [
    "0 -- Gensim lib\n",
    "1 -- python prog, LDA\n",
    "2 -- NLP\n",
    "\n",
    "  1- \"Natural language processing is a subfield of artificial intelligence.\",\n",
    "   2 \"Latent Dirichlet Allocation is a generative probabilistic model.\",\n",
    "   3 \"Topic modeling is used to identify topics present in a corpus of text.\",\n",
    "   4 \"Gensim is a popular Python library for topic modeling and document similarity.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "000de19a-8dd4-40e5-966b-25442d67ce78",
   "metadata": {},
   "source": [
    "# Assign topics to documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da343547-03b4-41b6-b1b6-1faba58a87a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1 - Topic: [(0, 0.047924496), (1, 0.047823634), (2, 0.9042519)]\n",
      "Document 2 - Topic: [(0, 0.048110045), (1, 0.9037409), (2, 0.048149098)]\n",
      "Document 3 - Topic: [(0, 0.91514033), (1, 0.042932756), (2, 0.0419269)]\n",
      "Document 4 - Topic: [(0, 0.04168155), (1, 0.9208708), (2, 0.037447672)]\n"
     ]
    }
   ],
   "source": [
    "# Assign topics to documents\n",
    "for i, doc in enumerate(processed_documents):\n",
    "    print(f\"Document {i+1} - Topic: {lda_model.get_document_topics(corpus[i])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17631d05-4439-4d2d-a59a-fe43b98bf5f9",
   "metadata": {},
   "source": [
    "#                   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cbf91b0-fe18-489a-a7f4-d97b0b4c1eed",
   "metadata": {},
   "source": [
    "# Mini Exercise hehe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60bad36b-18ab-422e-a1ce-c23b2254a9af",
   "metadata": {},
   "source": [
    "Instructions:\n",
    "\n",
    "Use the provided Python code to perform topic modeling on a set of sample documents.\n",
    "Modify the sample documents or add your own to see how the results change.\n",
    "Experiment with the number of topics (parameter: num_topics) in the LDA model. Observe how different numbers of topics impact the resu\n",
    "\n",
    "lMake a small insight on what you have observe when you change, increase, or decrease some parameters.(Short Essay lang)opics?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a1caf1-caf9-4fe1-b9b1-d6a1b23b4507",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
